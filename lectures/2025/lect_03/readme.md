# Лекция 3. Анализ и визуализация временного ряда бизнес-показателей


## 1. Введение. Роль временных рядов в бизнес-аналитике

Здравствуйте! Сегодня мы погрузимся в одну из самых важных тем для любого бизнес-аналитика — анализ временных рядов.

**Временной ряд** — это последовательность точек данных, собранных через равные промежутки времени. В бизнесе мы сталкиваемся с ними постоянно:
- **Финансы.** Ежедневные цены акций, курсы валют.
- **Ритейл.** Ежедневные, еженедельные или ежемесячные объемы продаж.
- **Маркетинг.** Ежечасное количество кликов на сайте, динамика подписчиков.
- **Операционная деятельность.** Ежедневное количество обращений в техподдержку, почасовая нагрузка на серверы.

Почему это так важно? Анализ временных рядов позволяет нам не просто смотреть на данные, а **извлекать из них закономерности, строить прогнозы и принимать обоснованные стратегические решения**. Например, спрогнозировав сезонный рост спроса на товар, мы можем заранее оптимизировать закупки и логистику.

### 1.1. Основные компоненты временного ряда

Любой временной ряд можно разложить на несколько ключевых составляющих, понимание которых — основа анализа.

1.  **Тренд (Trend).** Долгосрочное, общее направление движения данных. Тренд может быть восходящим (рост продаж), нисходящим (снижение доли рынка) или отсутствовать.
2.  **Сезонность (Seasonality).** Четкие, предсказуемые и повторяющиеся циклы. Например, продажи мороженого растут летом и падают зимой. Период сезонности фиксирован (день, неделя, год).
3.  **Циклы (Cycles).** Долгосрочные волнообразные колебания, не привязанные к фиксированному периоду. Классический пример — экономические циклы роста и рецессии, которые влияют на бизнес, но не имеют строгой периодичности.
4.  **Шум (Noise или Residual).** Случайные, нерегулярные колебания, которые остаются после исключения тренда, сезонности и циклов. Это непрогнозируемая часть данных.

Наша главная задача — "очистить" ряд от шума и разложить его на понятные компоненты, чтобы построить модель.

## 2. Подготовка к анализу. Инструменты и данные

Для работы в Python мы будем использовать стандартный набор библиотек для анализа данных.

-   **pandas.** Наш основной инструмент для работы с данными, особенно с временными рядами.
-   **matplotlib / seaborn.** Библиотеки для визуализации, которые помогут нам "увидеть" тренды и сезонность.
-   **statsmodels.** Мощная библиотека для статистического анализа, содержащая готовые инструменты для декомпозиции, тестов на стационарность и построения моделей, таких как ARIMA.

### 2.1. Работа с датами и временем

Первый шаг в любом анализе временных рядов — убедиться, что наши данные правильно интерпретируются как временные.

```python
import pandas as pd

data = {'Дата': ['2023-01-01', '2023-02-01', '2023-03-01'],
        'Продажи':}
df = pd.DataFrame(data)

# Преобразуем строковый столбец в формат datetime
df['Дата'] = pd.to_datetime(df['Дата'])

# Устанавливаем дату в качестве индекса
df.set_index('Дата', inplace=True)
```

**Почему это важно?** Когда дата становится индексом (`DatetimeIndex`), Pandas предоставляет массу удобных возможностей:
-   **Простая фильтрация по датам:** `df['2023-01':'2023-03']`
-   **Ресэмплинг:** Агрегация данных по другому временному интервалу (например, из ежедневных в ежемесячные).
-   **Скользящие окна:** Расчет скользящего среднего для сглаживания ряда.

### 2.2. Обработка пропущенных значений

В реальных бизнес-данных часто встречаются пропуски (`NaN`). Например, из-за сбоя в системе сбора данных. Игнорировать их нельзя.

-   **Удаление (`.dropna()`).** Самый простой метод, но он ведет к потере данных. Применим, если пропусков очень мало.
-   **Заполнение константой (`.fillna(0)`).** Просто, но может сильно исказить статистику (например, среднее).
-   **Заполнение средним/медианой.** Хороший компромисс, если в данных нет сильного тренда.
-   **Интерполяция (`.interpolate()`).** Один из лучших методов. Pandas "достраивает" пропущенное значение, проводя линию между двумя соседними известными точками. Идеально для данных, которые меняются плавно.

## 3. Исследовательский анализ (EDA)

Цель EDA — визуально исследовать данные, чтобы выдвинуть гипотезы об их структуре.

### 3.1. Визуализация и сглаживание

Простой линейный график — наш первый шаг. Он сразу может показать наличие тренда или явной сезонности.

**Скользящее среднее (Moving Average)** — это мощный инструмент для сглаживания ряда и выявления долгосрочного тренда. Мы рассчитываем среднее значение в "окне" определенного размера, которое скользит по ряду.

```python
# Рассчитываем скользящее среднее за 12 месяцев
df['rolling_mean_12'] = df['Продажи'].rolling(window=12).mean()

# Строим оба графика
df['Продажи'].plot(label='Исходные данные')
df['rolling_mean_12'].plot(label='Скользящее среднее', color='red')
plt.legend()
plt.show()
```
Чем больше окно (`window`), тем более сглаженным будет график.

### 3.2. Декомпозиция

Это процесс разложения временного ряда на его составляющие: тренд, сезонность и остаток (шум). Библиотека `statsmodels` делает это за одну команду.

```python
from statsmodels.tsa.seasonal import seasonal_decompose

decomposition = seasonal_decompose(df['Продажи'], model='additive')
decomposition.plot()
plt.show()
```

-   **`model='additive'`** используется, когда амплитуда сезонных колебаний примерно одинакова и не зависит от уровня ряда.
-   **`model='multiplicative'`** используется, когда сезонные колебания растут или уменьшаются вместе с трендом.

Декомпозиция помогает нам понять, какой компонент вносит наибольший вклад в динамику ряда.

## 4. Стационарность и корреляционный анализ

### 4.1. Стационарность

Большинство моделей временных рядов (включая ARIMA) требуют, чтобы ряд был **стационарным**. Это означает, что его статистические свойства (среднее, дисперсия, автокорреляция) не изменяются во времени. Ряд с явным трендом или сезонностью нестационарен.

**Как проверить на стационарность?**
-   **Визуально:** На графике не должно быть явного тренда или сезонности.
-   **Статистически:** С помощью **расширенного теста Дики-Фуллера (ADF Test)**.

Нулевая гипотеза теста: ряд нестационарен.
-   Если **p-value > 0.05**, мы не можем отвергнуть гипотезу (ряд, скорее всего, нестационарен).
-   Если **p-value < 0.05**, мы отвергаем гипотезу (ряд, скорее всего, стационарен).

### 4.2. Достижение стационарности

Самый распространенный метод — **дифференцирование (`.diff()`)**. Мы переходим от анализа абсолютных значений к анализу их изменений.

```python
# Дифференцирование первого порядка
df_diff = df['Продажи'].diff().dropna()
```
Если после первого дифференцирования ряд все еще нестационарен, можно применить второе.

### 4.3. Автокорреляция (ACF и PACF)

После того как мы сделали ряд стационарным, нам нужно понять, как его значения связаны друг с другом во времени. Для этого используются две функции:

1.  **ACF (Автокорреляционная функция):** Показывает корреляцию ряда с его "сдвинутыми" версиями (лагами). Она помогает определить порядок **MA(q)** компоненты. Если график ACF резко обрывается после `q` лагов, это наш кандидат на порядок `q`.

2.  **PACF (Частичная автокорреляционная функция):** Показывает "чистую" корреляцию ряда с его лагом, убирая влияние промежуточных лагов. Помогает определить порядок **AR(p)** компоненты. Если график PACF резко обрывается после `p` лагов, это наш кандидат на порядок `p`.

```python
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Строим графики для дифференцированного ряда
plot_acf(df_diff)
plot_pacf(df_diff)
plt.show()
```
Анализ этих графиков — ключевой шаг для подбора параметров модели ARIMA.

## 5. Прогнозное моделирование с ARIMA

**ARIMA (AutoRegressive Integrated Moving Average)** — это "рабочая лошадка" в прогнозировании временных рядов. Модель имеет три основных параметра `(p, d, q)`:

-   **p (AR).** Порядок авторегрессии. Сколько прошлых значений мы используем для прогноза. Определяется по графику **PACF**.
-   **d (I).** Порядок дифференцирования. Сколько раз мы дифференцировали ряд, чтобы сделать его стационарным.
-   **q (MA).** Порядок скользящего среднего. Сколько прошлых ошибок прогноза мы используем. Определяется по графику **ACF**.

### 5.1. Рабочий процесс моделирования

1.  **Разделение данных.** Делим весь набор данных на `train` (обучающая выборка) и `test` (тестовая выборка). На `train` мы обучаем модель, а на `test` — проверяем ее качество.
2.  **Обучение модели:**
    ```python
    from statsmodels.tsa.arima.model import ARIMA
    
    # Создаем и обучаем модель
    model = ARIMA(train_data, order=(p, d, q))
    model_fit = model.fit()
    print(model_fit.summary())
    ```
3.  **Прогнозирование:**
    ```python
    # Делаем прогноз на период тестовой выборки
    predictions = model_fit.predict(start=test_data.index, end=test_data.index[-1])
    ```
4.  **Оценка качества.** Сравниваем прогноз (`predictions`) с реальными данными (`test_data`). Основная метрика — **RMSE (Root Mean Squared Error)**, которая показывает среднюю ошибку прогноза в тех же единицах, что и сам ряд.
5.  **Прогноз на будущее.** После проверки модели на тестовых данных, мы можем использовать ее для прогноза за пределы имеющихся данных с помощью метода `.forecast()`.

## 6. Заключение и лабораторная работа

Сегодня мы рассмотрели полный цикл анализа временных рядов: от загрузки и очистки данных до построения и оценки прогнозной модели. Мы научились выявлять тренды, бороться с нестационарностью и подбирать параметры для модели ARIMA.

Теперь ваша задача — применить эти знания на практике.

Откройте рабочую тетрадь **`bi_lw_03_Time_Series_student.ipynb`**. В ней вы найдете пошаговые задания, которые повторяют все этапы, рассмотренные в этой лекции. В конце тетради вас ждет блок с индивидуальными заданиями для самостоятельного выполнения.



# Лабораторная работа 3.1 Анализ и визуализация временного ряда бизнес-показателей
---

### Цель работы

Основная цель данной работы — освоить практические навыки анализа, визуализации и прогнозирования временных рядов с использованием языка Python и ключевых библиотек (`pandas`, `statsmodels`, `matplotlib`).

По итогам выполнения работы вы научитесь:
-   Загружать и подготавливать временные данные для анализа (работа с датами, ресэмплинг).
-   Проводить исследовательский анализ (EDA) для выявления тренда, сезонности и других закономерностей.
-   Использовать методы сглаживания (скользящее среднее) и декомпозиции для анализа структуры ряда.
-   Проверять ряд на стационарность с помощью теста Дики-Фуллера и приводить его к стационарному виду.
-   Анализировать автокорреляционные функции (ACF и PACF) для подбора параметров модели.
-   Строить, обучать и оценивать качество прогнозной модели ARIMA.

---

### Инструкция по выполнению

1.  **Подготовка.** Откройте файл рабочей тетради `bi_lw_03_Time_Series_student.ipynb` в среде Google Colab или локально в Jupyter Notebook. Запустите первые ячейки, чтобы установить и импортировать все необходимые библиотеки.

2.  **Изучение материала.** Последовательно пройдите по **Частям 1-4** рабочей тетради. Выполните все учебные задания (Задания 1-23), чтобы ознакомиться с основными методами и техниками.

3.  **Выбор варианта.** В **Части 5** ("Индивидуальные задания для самостоятельной работы") найдите номер задания, соответствующий вашему варианту.

4.  **Решение.** В последней кодовой ячейке ноутбука, предназначенной для выполнения индивидуального задания, напишите код для решения **всех 5 пунктов** вашего варианта.
    -   Используйте соответствующий DataFrame (`gas_monthly` или `unemployment_df`), как указано в вашем задании.
    -   Для наглядности разделяйте код для каждого пункта комментариями (например, `# --- Пункт 1 ---`).
    -   Результат выполнения каждого пункта (таблицу, значение, график) необходимо вывести на экран с помощью `print()`, `display()` или `plt.show()`.

5.  **Сохранение.** После выполнения всех пунктов убедитесь, что вы сохранили ноутбук **со всеми результатами выполнения ячеек** (выводами кода и построенными графиками). Это обязательное требование для проверки.

---

### Требования к сдаче работы

1.  Создайте **публичный репозиторий** на GitHub или GitVerse (если вы еще этого не сделали).
2.  Загрузите в него ваш Jupyter Notebook (`.ipynb`) с выполненным вариантом. **Важно:** убедитесь, что в файле сохранены все результаты выполнения ячеек (выводы кода и графики).
3.  Скопируйте ссылку на ваш репозиторий.
4.  Прикрепите эту ссылку в поле для ответа на задание на платформе **Moodle**.

---

### Критерии оценки

Работа оценивается по шкале в **5 баллов**.

-   **5 баллов (Отлично):**
    -   Все 5 пунктов варианта выполнены полностью и корректно.
    -   Код написан аккуратно, легко читается.
    -   Все выводы (текст и графики) присутствуют в сохраненном файле.
    -   Работа сдана в соответствии с требованиями (ссылка на публичный репозиторий).

-   **4 балла (Хорошо):**
    -   Выполнены все 5 пунктов, но присутствуют 1-2 незначительные ошибки в коде или выводах.
    -   Либо 4 из 5 пунктов выполнены идеально, а один отсутствует/выполнен с грубыми ошибками.

-   **3 балла (Удовлетворительно):**
    -   Выполнено не менее 3 из 5 пунктов варианта.
    -   В коде присутствуют ошибки, которые влияют на правильность конечного результата, но общая логика решения верна.

-   **2 балла (Неудовлетворительно):**
    -   Выполнено менее 3 пунктов задания.
    -   Код содержит серьезные синтаксические или логические ошибки, не позволяющие получить корректный результат для большинства пунктов.

-   **0-1 балл:**
    -   Работа не сдана, сдана с нарушением требований (например, пустой файл, нет доступа к репозиторию) или выполнена лишь малая часть задания (например, только загрузка данных).

```

## ❓ Ответы на вопросы

### Где взять датасет `gas_monthly` для Части 5?

Файл `gas_monthly` **не нужно скачивать отдельно**. Это переменная (DataFrame), которая создается программно в процессе выполнения **Задания 9**.

Чтобы она появилась в памяти и стала доступна для выполнения индивидуальных заданий в Части 5, вам нужно последовательно запустить код из предыдущих частей:

**1. Загрузка сырых данных (Задание 7):**
В этой ячейке скачивается исходный файл и сохраняется в переменную `gas_df`.
```python
gas_url = "https://raw.githubusercontent.com/BosenkoTM/Python_for_scientists/refs/heads/main/data/US_gasoline_production.csv"
gas_df = pd.read_csv(gas_url, parse_dates=['date'], index_col='date')
```

**2. Создание нужного датасета (Задание 9):**
Здесь происходит ресемплинг (агрегация) данных по месяцам, в результате чего и появляется `gas_monthly`.
```python
# 'ME' — это alias для конца месяца (Month End) в новых версиях pandas
gas_monthly = gas_df.resample('ME').mean()
```

**Решение:** Просто выполните ячейки с кодом **Задания 7** и **Задания 9**. После этого переменная `gas_monthly` будет доступна для использования.
```
